function create(__helpers) {
  var str = __helpers.s,
      empty = __helpers.e,
      notEmpty = __helpers.ne;

  return function render(data, out) {
    out.w('<div class="pure-menu"><div id="menu-aside"><span class="pure-menu-heading">Indice</span><ul class="cd-accordion-menu animated"><li><a href="/"> Inicio</a></li><li><a href="/about"> De que se trata este libro</a></li><li><a href="/exercises_and_problems"> Sobre los ejercicios y problemas</a></li><li class="has-children"><input type="checkbox" name="chapter-1" id="chapter-1"><label for="chapter-1">Cap\u00edtulo 1</label><ul><a href="chapter-1"><li>Usando redes neuronales para reconocmiento de d\u00edgitos manuscritos</li></a><a href="chapter-1#perceptrons"><li>Perceptrons</li></a><a href="chapter-1#sigmoid_neurons"><li>Neuronas Sigmoid</li></a><a href="chapter-1#the_architecture_of_neural_networks"><li>Arquitectura de las redes neuronales</li></a><a href="chapter-1#a_simple_network_to_classify_handwritten_digits"><li>Una red simple para clasificar d\u00edgitos escritos a mano</li></a><a href="chapter-1#learning_with_gradient_descent"><li>Aprendiendo con gradiente descendiente</li></a><a href="chapter-1#implementing_our_network_to_classify_digits"><li>Implementaci\u00f3n de nuestra red para clasificar d\u00edgitos</li></a><a href="chapter-1#toward_deep_learning"><li>Hacia el aprendizaje profundo</li></a></ul></li><li class="has-children"><input type="checkbox" name="chapter-2" id="chapter-2"><label for="chapter-2">Cap\u00edtulo 2</label><ul><a href="chapter-2#warm_up_a_fast_matrix-based_approach_to_computing_the_output_from_a_neural_network"><li>Como trabaja el algoritmo de retropropagaci\u00f3n</li></a><a href="chapter-2#warm_up_a_fast_matrix-based_approach_to_computing_the_output_from_a_neural_network"><li>Calentamiento: Un enfoque r\u00e1pido basado en una matriz que calcula la salida de\nuna red\nneuronal</li></a><a href="chapter-2#the_two_assumptions_we_need_about_the_cost_function"><li>Dos supuestos que necesitamos acerca de la funci\u00f3n de costo</li></a><a href="chapter-2#the_hadamard_product_@s_\\odot_t@"><li>El producto Hadamard, @s \\odot t@</li></a><a href="chapter-2#the_four_fundamental_equations_behind_backpropagation"><li>Las cuatro ecuaciones fundamentales detr\u00e1s del algoritmo de retroprogramaci\u00f3n\n(backpropagation)</li></a><a href="chapter-2#proof_of_the_four_fundamental_equations_(optional)"><li>Prueba de las cuatro ecuaciones fundamentales (opcional)</li></a><a href="chapter-2#the_backpropagation_algorithm"><li>El algoritmo de retropropagaci\u00f3n (backpropagation)</li></a><a href="chapter-2#the_code_for_backpropagation"><li>El c\u00f3digo para retropropagaci\u00f3n</li></a><a href="chapter-2#in_what_sense_is_backpropagation_a_fast_algorithm"><li>\u00bfEn qu\u00e9 sentido el algoritmo de retropropagaci\u00f3n es r\u00e1pido?</li></a><a href="chapter-2#backpropagation_the_big_picture"><li>Retropropagaci\u00f3n: Un panorama general</li></a></ul></li><li class="has-children"><input type="checkbox" name="chapter-3" id="chapter-3"><label for="chapter-3">Cap\u00edtulo 3</label><ul><a href="chapter-3#the_cross-entropy_cost_function"><li>La funci\u00f3n de costo basada en la entrop\u00eda cruzada</li></a><a href="chapter-3#overfitting_and_regularization"><li>Desbordamiento y regularizaci\u00f3n</li></a><a href="chapter-3#weight_initialization"><li>Inicializaci\u00f3n de pesos</li></a><a href="chapter-3#handwriting_recognition_revisited_the_code"><li>Reconocimiento de escritura a mano: C\u00f3digo</li></a><a href="chapter-3#how_to_choose_a_neural_network&#39;s_hyper-parameters"><li>\u00bfC\u00f3mo elegir los hiperpar\u00e1metros de una red neuronal?</li></a><a href="chapter-3#other_techniques"><li>Otras t\u00e9cnicas</li></a></ul></li><li class="has-children"><input type="checkbox" name="chapter-4" id="chapter-4"><label for="chapter-4">Cap\u00edtulo 4</label><ul><a href="chapter-4#two_caveats"><li>Dos advertencias</li></a><a href="chapter-4#universality_with_one_input_and_one_output"><li>Universalidad con una entrada y una salida</li></a><a href="chapter-4#many_input_variables"><li>Muchas variables de entrada</li></a><a href="chapter-4#extension_beyond_sigmoid_neurons"><li>Extensi\u00f3n m\u00e1s all\u00e1 de neuronas sigmoide</li></a><a href="chapter-4#fixing_up_the_step_functions"><li>Fijaci\u00f3n de las funciones de paso</li></a><a href="chapter-4#conclusion"><li>Conclusi\u00f3n</li></a></ul></li><li class="has-children"><input type="checkbox" name="chapter-5" id="chapter-5"><label for="chapter-5">Cap\u00edtulo 5</label><ul><a href="chapter-5#the_vanishing_gradient_problem"><li>El problema "desapaci\u00f3n del gradiente"</li></a><a href="chapter-5#what&#39;s_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>Qu\u00e9 est\u00e1 causando el problema "desaparaci\u00f3n de gradiente? Gradientes inestables\nen redes neuronales\nprofundas</li></a><a href="chapter-5#unstable_gradients_in_more_complex_networks"><li>Gradientes inestables en redes m\u00e1s complejas</li></a><a href="chapter-5#other_obstacles_to_deep_learning"><li>Otros obstaculos en el aprendizaje profundo</li></a></ul></li><li class="has-children"><input type="checkbox" name="chapter-6" id="chapter-6"><label for="chapter-6">Cap\u00edtulo 6</label><ul><a href="chapter-6#introducing_convolutional_networks"><li>Introducci\u00f3n a las redes convolucionales</li></a><a href="chapter-6#convolutional_neural_networks_in_practice"><li>Redes neuronales convolucionales en la pr\u00e1ctica</li></a><a href="chapter-6#the_code_for_our_convolutional_networks"><li>El algoritmo para nuestras redes convolucionales</li></a><a href="chapter-6#recent_progress_in_image_recognition"><li>Recientes avances en reconocimiento de imagen</li></a><a href="chapter-6#other_approaches_to_deep_neural_nets"><li>Otros enfoques de redes neuronales profundas</li></a><a href="chapter-6#on_the_future_of_neural_networks"><li>Sobre el futuro de las redes neuronales</li></a></ul></li><li><a href="sai.html"> Apendice: \u00bfHay un<em>simple</em> algoritmo para inteligencia?</a></li><li><a href="acknowledgements.html"> Agradecimientos</a></li><li><a href="faq.html"> Preguntas frecuentes</a></li></ul></div><div id="about-book"><p>Esta traducci\u00f3n est\u00e1 siendo llevada a cabo por <a href="http://www.davidenq.com">David N\u00fa\u00f1ez</a> Puedes contribuir con el proyecto y la traducci\u00f3n realizando un fork en\ngithub.\n<ul class="soc"><li><a class="soc-github soc-icon-last" href="https://github.com/davidenq/web-redes-neuronales-y-aprendizaje-profundo"></a></li></ul><br> Si deseas leer el libro en su versi\u00f3n original visita <a href="http://neuralnetworksanddeeplearning.com">Neural Networks and Deep Learning.</a></p></div></div>');
  };
}
(module.exports = require("marko").c(__filename)).c(create);